\section{Introduction}
\label{sec:intro}

As VLM-driven agents begin to operate productivity software, the capability that matters most in everyday use: editing existing PowerPoint (PPT) decks with structure-aware precision, remains largely unverified and under-supported~\cite{openai2025chatgptagent}. Image- or PDF-based formulations discard deck semantics (formats, placeholders, shape trees), while text-to-slides pipelines emphasize generation and ignore edit-in-place constraints~\cite{jung2025talkslideslanguagedrivenagents,ge2025autopresentdesigningstructuredvisuals}. This gap matters because most decks are refined through revision, not from scratch, making reliable layout reasoning and non-destructive modification the realistic bar for agentic PPT capability. Yet we still lack a benchmark that asks the practical question: \emph{can todayâ€™s multimodal agents reliably edit existing decks with high instruction fidelity and visual quality?}

Reliable PPT editing is intrinsically hard. Rasterized ``image editing'' views discard the object- and style-level structure that makes editing precise: fonts and paragraphs, shape geometries, z-order, theme colors, slide masters, and cross-references are all lost once a deck is treated as a bitmap. The same instruction (\eg, ``make the subtitle 18pt and align the two logos to the grid'') can require multiple coordinated actions across several slides, conditioned on the existing layout and theme. Evaluation is equally subtle: a change can be syntactically valid yet semantically wrong or aesthetically poor. These failure modes are systematically invisible to benchmarks that only check final text strings, API-level diffs, or pixel similarity, and they motivate a benchmark that treats PPT editing as a structured program over deck semantics, with explicit scoring of both instruction following and visual quality.

Our motivation is grounded in how presentations are actually made and maintained. In professional and academic settings, most decks do not begin from a completely blank canvas; they evolve through continuous revision: merging slides from prior talks, adapting templates for new audiences, and polishing visual hierarchy. Editing reveals whether an agent truly understands the structure already present: the agent must locate the correct element, reason about its relationships (alignment, grouping, z-order), and modify it without collateral changes elsewhere. To capture this reality, we introduce \textbf{PPTArena}, a benchmark designed explicitly for agentic PowerPoint editing on real decks. PPTArena assembles 100 real-world source decks and 2{,}125 slides into 800+ discrete, human-specified edits that range from local text updates to compound, cross-slide transformations, such as deck-wide theme flips, accessibility passes, and multi-step layout repairs. Each case bundles an initial deck, a fully specified target deck, and a \emph{style-aware rubric} that disambiguates correctness at the level of content, typography, layout, and color roles. Representative tasks are illustrated in \Cref{fig:teaser}, including filling in missing poster content while preserving hierarchy, flipping theme color roles consistently across a deck, fixing layout and format across related slides, and translating slide content while maintaining charts and structure. To our knowledge, PPTArena is the first benchmark that (i) treats PPT editing as a structured, causal program over deck semantics, (ii) ships element-level ground truths, style targets, and error rubrics to disambiguate correctness, and (iii) uses dual instruction-following and visual judges that allow diverse configurations of edits while maintaining task coherence.


Complementing the benchmark, we present \textbf{PPTPilot}, a structure-aware pilot agent for robust, fine-grained PPT editing. PPTPilot decomposes each natural-language instruction into a sequence of semantic operations, chooses between high-level APIs (\eg, \texttt{python-pptx}) and direct XML patching, and validates the outcome against task-specific targets. Two design choices are key: \emph{structure-aware planning}, where the agent parses slide masters, placeholders, shape trees, text, and visual data before editing, and \emph{deterministic execution}, where XML-level patches and strict schemas give exact control over fonts, theme color slots, positions, and master-level changes while programmatic tools handle repetitive global operations (\eg, translation, bulk normalization). An iterative plan-edit-verify loop, coupled with XML validation and visual checks, improves robustness on visually demanding and long-horizon edits.


We evaluate a broad spectrum of baselines on PPTArena, including strong proprietary PPT agents (\eg, ChatGPT Agent~\cite{openai2025chatgptagent} and MiniMax Agent~\cite{minimax_m2_2025}), extended-thinking VLM configurations, and ablations of PPTPilot. Even with generous prompting and tool access, existing systems struggle to balance instruction fidelity with visual/layout quality on compound, multi-step edits, and they frequently fail on cross-slide dependencies and master-level style changes surfaced by our benchmark. In contrast, PPTPilot achieves substantially higher scores, improving over strong proprietary agents and frontier VLM systems by more than 10 percentage points on compound, layout-sensitive, and cross-slide edits, while maintaining competitive performance on simpler cases. Nonetheless, PPTPilot and all evaluated agents significantly fail on hard, visually dependent tasks, suggesting both the difficulty of PPTArena and the headroom for future research.

Our key contributions are threefold:
(1) \textbf{PPTArena}, a benchmark for agentic PowerPoint editing that (i) operates on deck-native structure rather than rasterized slides, (ii) offers a taxonomy of single- and multi-edit tasks that stress structural grounding, cross-slide consistency, accessibility, and narrative intent, and (iii) pairs each case with element-level ground truths, style targets, and a dual-judge protocol that separately measures instruction fidelity and visual/layout quality, extending beyond prior PPT evaluation setups~\cite{guo-etal-2024-pptc,ge2025autopresentdesigningstructuredvisuals}.
(2) \textbf{PPTPilot}, a structure-aware pilot agent that plans edits over semantic elements and executes them via a hybrid of high-level programmatic tools and deterministic OOXML patching, with routing, strict schemas, and iterative verification designed for controllability, reliability, and transparency.
(3) \textbf{A comprehensive empirical study} of proprietary agents, open VLMs, and PPTPilot variants on PPTArena, revealing that the benchmark is challenging even for state-of-the-art systems.

